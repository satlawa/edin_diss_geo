{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "from glob import glob\n",
    "#from os import listdir\n",
    "#from os.path import splitext\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_img = '/mnt/sda1/tiles_2018_wien/'\n",
    "#dir_img = '/mnt/sda1/tiles_2018_zell_am_see/'\n",
    "#dir_img = '/media/philipp/DATA/2018_wien/'\n",
    "dir_img = '/media/philipp/DATA/2017_mariazell/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_ortho = []\n",
    "ids_dsm = []\n",
    "ids_ground_truth = []\n",
    "\n",
    "sufix_ortho = 'ortho/'\n",
    "sufix_dsm = 'dsm/'\n",
    "sufix_gt = 'ground_truth/'\n",
    "\n",
    "# loop over all files found in directory\n",
    "for file in os.listdir(dir_img+sufix_ortho):\n",
    "    # create path to ground truth\n",
    "    path_dsm = dir_img + sufix_dsm + 'tile_dsm' + file[file.rfind('_'):]\n",
    "    path_gt = dir_img + sufix_gt + 'tile_ground_truth' + file[file.rfind('_'):]\n",
    "    # if file is .tif and the ID is alo found in the grooound truth dictonary\n",
    "    if file[file.rfind('.'):] == '.tif' and os.path.isfile(path_gt) and os.path.isfile(path_dsm):\n",
    "        # add path to lists\n",
    "        ids_ortho.append(dir_img + sufix_ortho + file)\n",
    "        ids_dsm.append(path_dsm)\n",
    "        ids_ground_truth.append(path_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13464"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_292929.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_295350.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_304543.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_300619.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_298260.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_297600.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_293974.tif\n"
     ]
    }
   ],
   "source": [
    "print(ids_ortho[0])\n",
    "print(ids_ortho[288])\n",
    "print(ids_ortho[399])\n",
    "print(ids_ortho[666])\n",
    "print(ids_ortho[5000])\n",
    "print(ids_ortho[6969])\n",
    "print(ids_ortho[9990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_292929.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_295350.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_304543.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_300619.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_298260.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_297600.tif\n",
      "/media/philipp/DATA/2017_mariazell/ortho/tile_ortho_293974.tif\n"
     ]
    }
   ],
   "source": [
    "print(ids_ortho[0])\n",
    "print(ids_ortho[288])\n",
    "print(ids_ortho[399])\n",
    "print(ids_ortho[666])\n",
    "print(ids_ortho[5000])\n",
    "print(ids_ortho[6969])\n",
    "print(ids_ortho[9990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdalconst\n",
    "\n",
    "def tif2array(input_file, dtype=np.uint8):\n",
    "    \"\"\"\n",
    "    read GeoTiff and convert to numpy.ndarray.\n",
    "    inputs:\n",
    "        input_file (str) : the name of input GeoTiff file.\n",
    "    return:\n",
    "        image(np.array) : image for each bands\n",
    "        dataset : for gdal's data drive.\n",
    "    \"\"\"\n",
    "    dataset = gdal.Open(input_file, gdal.GA_ReadOnly)\n",
    "    \n",
    "    if dataset is None:\n",
    "        return None\n",
    "    \n",
    "    # Allocate our array using the first band's datatype\n",
    "    image_datatype = dataset.GetRasterBand(1).DataType\n",
    "    image = np.zeros((dataset.RasterYSize, dataset.RasterXSize, dataset.RasterCount),\n",
    "                     dtype=dtype)\n",
    "    \n",
    "    # Loop over all bands in dataset\n",
    "    for b in range(dataset.RasterCount):\n",
    "        # Remember, GDAL index is on 1, but Python is on 0 -- so we add 1 for our GDAL calls\n",
    "        band = dataset.GetRasterBand(b + 1)\n",
    "        # Read in the band's data into the third dimension of our array\n",
    "        image[:, :, b] = band.ReadAsArray()#buf_type=gdalconst.GDT_Byte)\n",
    "        \n",
    "    #image = image[2:-2,2:-2,:]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_img(img, x, y):\n",
    "    \"\"\"\n",
    "    cut input numpy array to the width(x) and height(y)\n",
    "    inputs:\n",
    "        img (np.array) : image as numpy array\n",
    "        x (int) : target width\n",
    "        y (int) : target height\n",
    "    return:\n",
    "        img (np.array) : image cutted to the target width(x) and height(y)\n",
    "    \"\"\"\n",
    "    # set pixel sizes\n",
    "    x_i, y_i, z_i = img.shape\n",
    "    # dict to store the sliceing information\n",
    "    d = {}\n",
    "    \n",
    "    for var, var_i, key in [(x, x_i, 'x'), (y, y_i, 'y')]:\n",
    "        # if image pixel size is grater than the target pixel size\n",
    "        if (var_i > var):\n",
    "            # if even cut same amount of pixels from both sides\n",
    "            if var_i%2 == 0:\n",
    "                sub = int(var_i/2 - var/2)\n",
    "                d[key+'0'] = sub\n",
    "                d[key+'1'] = sub\n",
    "            # if odd cut 1 pixel more from right/bottom\n",
    "            else:\n",
    "                sub = int(var_i/2 - var/2)\n",
    "                d[key+'0'] = sub\n",
    "                d[key+'1'] = sub + 1\n",
    "        else:\n",
    "            print('image too small')\n",
    "    # cut image\n",
    "    img = img[d['x0']:-d['x1'],d['y0']:-d['y1']]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass ids_ortho, ids_dsm, ids_dtm, ids_slope\n",
    "def create_array(ids, dtype):\n",
    "    \"\"\"\n",
    "    creates numpy array with all images stacked\n",
    "    inputs:\n",
    "        ids (list) : list of paths to image files\n",
    "        dtype (dtype) : dtype for storing the loaded image\n",
    "    return:\n",
    "        arr (np.array) : numpy array containing all the images stacked\n",
    "    \"\"\"\n",
    "    \n",
    "    imgs = []\n",
    "    \n",
    "    if dtype == np.uint8:\n",
    "        # add all\n",
    "        for i in ids:\n",
    "            # load image to numpy array\n",
    "            img = tif2array(i, np.uint8)\n",
    "            # cut into right shape\n",
    "            img = cut_img(img, 512, 512)\n",
    "            # append array to list\n",
    "            imgs.append(img)\n",
    "            \n",
    "        # convert list with arrays to numpy array\n",
    "        arr = np.stack(imgs, axis=0)\n",
    "        print(arr.shape)\n",
    "            \n",
    "        # calculate mean\n",
    "        #mean = np.mean(arr, dtype='float32')\n",
    "        # calculate standard deviation\n",
    "        #std = np.std(arr, dtype='float32')\n",
    "    \n",
    "    else:\n",
    "        # add all\n",
    "        for i in ids:\n",
    "            \n",
    "            # load image to numpy array\n",
    "            img = tif2array(i, dtype)\n",
    "            # cut into right shape\n",
    "            img = cut_img(img, 512, 512)\n",
    "            # append array to list\n",
    "            imgs.append(img)\n",
    "            x, y, z = img.shape\n",
    "\n",
    "        # convert list with arrays to numpy array\n",
    "        arr = np.stack(imgs, axis=0)\n",
    "        arr[arr < 0] = np.nan\n",
    "        print(arr.shape)\n",
    "\n",
    "        # calculate mean\n",
    "        #mean = np.nanmean(arr, dtype='float32')\n",
    "        # calculate standard deviation\n",
    "        #std = np.nanstd(arr, dtype='float32')\n",
    "        # convert nan to 0\n",
    "        arr = np.nan_to_num(arr)\n",
    "    \n",
    "    # normalize data\n",
    "    #arr = (arr - mean) / std\n",
    "    \n",
    "    return arr#, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1464, 512, 512, 4)\n",
      "(1464, 512, 512, 1)\n",
      "(1464, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "start = 12000\n",
    "end = 13464\n",
    "arr_ortho = create_array(ids_ortho[start:end], np.uint8)\n",
    "arr_dsm = create_array(ids_dsm[start:end], np.float16)\n",
    "arr_ground_truth = create_array(ids_ground_truth[start:end], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create mask\n",
    "m = np.ma.make_mask(arr_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mask\n",
    "arr_ortho *= m\n",
    "arr_dsm *= m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values under and over threshhold to 0\n",
    "arr_dsm[arr_dsm < 0] = 0\n",
    "arr_dsm[arr_dsm > 49] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 256\n",
    "arr_ortho_256 = np.concatenate([arr_ortho[:, :256, :256], \\\n",
    "arr_ortho[:, 256:, :256], \\\n",
    "arr_ortho[:, :256, 256:], \\\n",
    "arr_ortho[:, 256:, 256:]], axis=0)\n",
    "\n",
    "arr_dsm_256 = np.concatenate([arr_dsm[:, :256, :256], \\\n",
    "arr_dsm[:, 256:, :256], \\\n",
    "arr_dsm[:, :256, 256:], \\\n",
    "arr_dsm[:, 256:, 256:]], axis=0)\n",
    "\n",
    "arr_ground_truth_256 = np.concatenate([arr_ground_truth[:, :256, :256], \\\n",
    "arr_ground_truth[:, 256:, :256], \\\n",
    "arr_ground_truth[:, :256, 256:], \\\n",
    "arr_ground_truth[:, 256:, 256:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del arr_ortho\n",
    "del arr_dsm\n",
    "del arr_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5856, 256, 256, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_ortho_256.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5856, 256, 256, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_ground_truth_256.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete empty tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices with just zeros\n",
    "#idx_delete = []\n",
    "#for i in range(0,arr_ortho_256.shape[0]):\n",
    "#    if arr_ortho_256[i].sum() == 0 or arr_ground_truth_256[i].sum() == 0:\n",
    "#        idx_delete.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices with just zeros\n",
    "#arr_ortho.shape[]\n",
    "# limit of 0 to pass\n",
    "limit_gt = arr_ortho_256.shape[1] ** 2 / 2\n",
    "limit_ortho = limit_gt * 4\n",
    "\n",
    "idx_delete = []\n",
    "for i in range(0,arr_ortho_256.shape[0]):\n",
    "    #np.count_nonzero(X==0)\n",
    "    if np.count_nonzero(arr_ortho_256[i]==0) > limit_ortho or \\\n",
    "       np.count_nonzero(arr_ground_truth_256[i]==0) > limit_ortho:\n",
    "        idx_delete.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete images with just zeros\n",
    "arr_ortho_256 = np.delete(arr_ortho_256, idx_delete, axis=0)\n",
    "arr_dsm_256 = np.delete(arr_dsm_256, idx_delete, axis=0)\n",
    "arr_ground_truth_256 = np.delete(arr_ground_truth_256, idx_delete, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4820, 256, 256, 4)\n",
      "(4820, 256, 256, 1)\n",
      "(4820, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(arr_ortho_256.shape)\n",
    "print(arr_dsm_256.shape)\n",
    "print(arr_ground_truth_256.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4820"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_ortho_256.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7367"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = 9641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_file_name  = \"/home/philipp/Data/edin_dataset/dataset_512_1.h5\"\n",
    "ds_file_name  = \"/media/philipp/DATA/dataset/dataset_256_ba_dsm.h5\"\n",
    "\n",
    "tile_size = 256\n",
    "\n",
    "#ortho_shape = (len(arr_ortho), 512, 512, 4)\n",
    "#dsm_shape = (len(arr_dsm), 512, 512, 1)\n",
    "ortho_shape = (arr_ortho_256.shape[0], tile_size, tile_size, 4)\n",
    "dsm_shape = (arr_dsm_256.shape[0], tile_size, tile_size, 1)\n",
    "gt_shape = (arr_ground_truth_256.shape[0], tile_size, tile_size, 1)\n",
    "\n",
    "with h5py.File(ds_file_name, 'w') as hf:\n",
    "    hf.create_dataset('x_ortho', data=arr_ortho_256, shape=ortho_shape, dtype=np.uint8, chunks=(100,tile_size,tile_size,4))\n",
    "    hf.create_dataset('x_dsm', data=arr_dsm_256, shape=dsm_shape, dtype=np.float16, chunks=(100,tile_size,tile_size,1))\n",
    "    hf.create_dataset('y_ground_truth', data=arr_ground_truth_256, shape=gt_shape, dtype=np.uint8, chunks=(100,tile_size,tile_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ortho & dsm & ground truth\n",
    "ds_file_name  = \"/media/philipp/DATA/dataset/dataset_256_ba_dsm.h5\"\n",
    "\n",
    "tile_size = arr_ortho_256.shape[1]\n",
    "\n",
    "hdf5_store = h5py.File(ds_file_name, 'a')\n",
    "# seting space to shape 200,512,512,4\n",
    "x_ortho = hdf5_store.create_dataset(\"x_ortho\", (91000,tile_size,tile_size,4), dtype=np.uint8)\n",
    "x_ortho[:arr_ortho_256.shape[0],:,:,:] = arr_ortho_256\n",
    "\n",
    "x_dsm = hdf5_store.create_dataset(\"x_dsm\", (91000,tile_size,tile_size,1), dtype=np.float16)\n",
    "x_dsm[:arr_dsm_256.shape[0],:,:,:] = arr_dsm_256\n",
    "\n",
    "x_ground_truth = hdf5_store.create_dataset(\"y_ground_truth\", (91000,tile_size,tile_size,1), dtype=np.uint8)\n",
    "x_ground_truth[:arr_ground_truth_256.shape[0],:,:,:] = arr_ground_truth_256\n",
    "\n",
    "hdf5_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file_name  = \"/media/philipp/DATA/dataset/dataset_256_ba_dsm.h5\"\n",
    "\n",
    "tile_size = arr_ortho_256.shape[1]\n",
    "\n",
    "hdf5_store = h5py.File(ds_file_name, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"dataset_256_ba_dsm.h5\" (mode r+)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_dsm', 'x_ortho', 'y_ground_truth']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hdf5_store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = 86235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: 86235 to: 91055\n"
     ]
    }
   ],
   "source": [
    "last_new = last+arr_ortho_256.shape[0]\n",
    "print('from: '+ str(last) + ' to: ' + str(last_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last = 39543\n",
    "#last_new = last+arr_ortho_256.shape[0]\n",
    "#print('from: '+ str(last) + ' to: ' + str(last_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset\n",
    "x_ortho = hdf5_store['x_ortho']\n",
    "# assign data \n",
    "x_ortho[last:last_new,:,:,:] = arr_ortho_256\n",
    "\n",
    "# set dataset\n",
    "x_dsm = hdf5_store['x_dsm']\n",
    "# assign data \n",
    "x_dsm[last:last_new,:,:,:] = arr_dsm_256\n",
    "\n",
    "# set dataset\n",
    "y_ground_truth = hdf5_store['y_ground_truth']\n",
    "# assign data \n",
    "y_ground_truth[last:last_new,:,:,:] = arr_ground_truth_256\n",
    "\n",
    "hdf5_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = last_new\n",
    "del arr_ortho_256\n",
    "del arr_ground_truth_256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:46868 -> wien\n",
    "# 46868: -> 91000 mariazell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
